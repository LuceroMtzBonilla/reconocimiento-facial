{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08c06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout,Activation,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6962317",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 2   \n",
    "epochs = 3\n",
    "batch_size = 20  \n",
    "num_train = 143  \n",
    "num_val = 27\n",
    "num_test = 36   \n",
    "iw, ih = 192,192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b0497a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (65985737.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    en este caso los directorios estan de m√°s, dado que ya se definieron arriba, pero sirve para visualizar lo que se hace.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_d = r\"\"\n",
    "val_d = r\"\"\n",
    "test_d = r\"\"\n",
    "   \n",
    "#tipos de transformaciones en las que se basa la generacion de imagenes\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.15,\n",
    "                                   width_shift_range=0.1, \n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=False \n",
    "                                   )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_d,\n",
    "    target_size=(iw, ih),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_d,\n",
    "    target_size=(iw, ih),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test = val_datagen.flow_from_directory(\n",
    "    test_d,\n",
    "    target_size=(iw, ih),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Found 143 images belonging to 2 classes.\n",
    "Found 27 images belonging to 2 classes.\n",
    "Found 36 images belonging to 1 classes.\n",
    "epoch_steps = num_train // batch_size\n",
    "val_steps = num_val // batch_size\n",
    "test_steps = num_test // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "path_model = ''\n",
    "\n",
    "pre_trained_model = load_model(path_model)\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2750a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#capas convolucionales pre entrenadas\n",
    "model.add(pre_trained_model.layers[0])\n",
    "model.add(pre_trained_model.layers[1])\n",
    "model.add(pre_trained_model.layers[2])\n",
    "model.add(pre_trained_model.layers[3])\n",
    "model.add(pre_trained_model.layers[4])\n",
    "model.add(pre_trained_model.layers[5])\n",
    "model.add(pre_trained_model.layers[6])\n",
    "model.add(pre_trained_model.layers[7])\n",
    "model.add(pre_trained_model.layers[8])\n",
    "model.add(pre_trained_model.layers[9])\n",
    "\n",
    "#clasificador\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#congelamos los pesos de las capas pre entrenadas\n",
    "for layer in pre_trained_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c43ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 20,\n",
    "    verbose = 1, \n",
    "    validation_data = val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab6d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
