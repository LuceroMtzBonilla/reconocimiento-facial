{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08c06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout,Activation,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6962317",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 2   \n",
    "epochs = 3\n",
    "batch_size = 20  \n",
    "num_train = 114 \n",
    "num_val = 42\n",
    "iw, ih = 192,192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b0497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 images belonging to 2 classes.\n",
      "Found 42 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_d = r\"/Users/luceromartinezbonilla/Desktop/redes neuronales/reconocimiento_facial/archive/training\"\n",
    "val_d = r\"/Users/luceromartinezbonilla/Desktop/redes neuronales/reconocimiento_facial/archive/val\"\n",
    "   \n",
    "#tipos de transformaciones en las que se basa la generacion de imagenes\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.15,\n",
    "                                   width_shift_range=0.1, \n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=False \n",
    "                                   )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_d,\n",
    "    target_size=(iw, ih),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_d,\n",
    "    target_size=(iw, ih),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps = num_train // batch_size\n",
    "val_steps = num_val // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2822e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "path_model = '/Users/luceromartinezbonilla/Desktop/redes neuronales/reconocimiento_facial/archive/modelo1_rec_facial.h5'\n",
    "\n",
    "pre_trained_model = load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2750a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#capas convolucionales pre entrenadas\n",
    "model.add(pre_trained_model.layers[0])\n",
    "model.add(pre_trained_model.layers[1])\n",
    "model.add(pre_trained_model.layers[2])\n",
    "model.add(pre_trained_model.layers[3])\n",
    "model.add(pre_trained_model.layers[4])\n",
    "model.add(pre_trained_model.layers[5])\n",
    "model.add(pre_trained_model.layers[6])\n",
    "model.add(pre_trained_model.layers[7])\n",
    "model.add(pre_trained_model.layers[8])\n",
    "model.add(pre_trained_model.layers[9])\n",
    "\n",
    "#clasificador\n",
    "model.add(Dense(units = 40, name = 'media_dense', activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1, name = 'output_dense', activation = 'sigmoid' ))\n",
    "\n",
    "#congelamos los pesos de las capas pre entrenadas\n",
    "for layer in pre_trained_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c43ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.6519 - accuracy: 0.6404 - val_loss: 0.7712 - val_accuracy: 0.3571\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.5775 - accuracy: 0.6667 - val_loss: 0.6958 - val_accuracy: 0.3810\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.5344 - accuracy: 0.7018 - val_loss: 0.5836 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.4583 - accuracy: 0.8246 - val_loss: 0.5485 - val_accuracy: 0.6905\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.4547 - accuracy: 0.7982 - val_loss: 0.5231 - val_accuracy: 0.6905\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.3901 - accuracy: 0.8596 - val_loss: 0.4640 - val_accuracy: 0.8095\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.3471 - accuracy: 0.8860 - val_loss: 0.4140 - val_accuracy: 0.8810\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.3456 - accuracy: 0.8772 - val_loss: 0.3734 - val_accuracy: 0.9048\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.3126 - accuracy: 0.9211 - val_loss: 0.3238 - val_accuracy: 0.9286\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2979 - accuracy: 0.9123 - val_loss: 0.3022 - val_accuracy: 0.9286\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.2757 - accuracy: 0.9035 - val_loss: 0.2849 - val_accuracy: 0.9286\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2609 - accuracy: 0.9298 - val_loss: 0.2606 - val_accuracy: 0.9524\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2428 - accuracy: 0.9386 - val_loss: 0.2282 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2468 - accuracy: 0.9298 - val_loss: 0.2165 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.2205 - accuracy: 0.9474 - val_loss: 0.2096 - val_accuracy: 0.9762\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.2467 - accuracy: 0.9123 - val_loss: 0.1894 - val_accuracy: 0.9762\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.1975 - accuracy: 0.9474 - val_loss: 0.1757 - val_accuracy: 0.9762\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.1602 - accuracy: 0.9737 - val_loss: 0.1621 - val_accuracy: 0.9762\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.2057 - accuracy: 0.9298 - val_loss: 0.1712 - val_accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.2237 - accuracy: 0.9123 - val_loss: 0.1658 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa87ef63700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 20,\n",
    "    verbose = 1, \n",
    "    validation_data = val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab6d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
